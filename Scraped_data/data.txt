Skip to content
Navigation Menu
junaidulhassan
/
ConversifyAI
Type / to search
Code
Issues
Pull requests
Actions
Projects
Wiki
Security
Insights
Settings
ConversifyAI
Public
Unpin
Unwatch1
Fork 1
 Starred 2
junaidulhassan/ConversifyAI
 master
1 Branch
0 Tags
t
Add file
Add file
Code
Folders and files
Name	Last commit message	Last commit date

Latest commit
junaidulhassan
Update requirements.txt
09ed76d
 · 
History
47 Commits


Backend
	
Add Image Generation function
	


Frontend
	
Add Image Generation function
	


Images
	
Add Images Generation Functions
	


Jupyter Files
	
Add Image Generation function
	


Web-Content/Docs/Chroma
	
Updates
	


__pycache__
	
Add Image Generation function
	


text_file.txt
	
Updation
	


LLM.py
	
Update LLM.py
	


RAG.py
	
Add Images Generation Functions
	


RAG_QnA.py
	
Add Image Generation function
	


README.md
	
Update README.md
	


Web-Pilot.py
	
Add Image Generation function
	


api_token.py
	
Update api_token.py
	


chatbot.py
	
Update chatbot.py
	


requirements.txt
	
Update requirements.txt
	


scrap.py
	
Update scrap.py
	
Repository files navigation
README
Conversify AI

Application Name: Conversify AI

Conversify AI is a sophisticated RAG (Retrieval Augmented Generation) application designed to interact seamlessly with website content, including vlogs and other materials. This application allows users to paste the URL of any website they want to engage with, enabling question-answering, summarization, and more, all with ease.

Key Components
Mistral-7b-instruct v0.3 LLM: Utilized for text generation.
Langchain Library: Used for prompt engineering and RAG application development.
Chroma DB: Employed as a vector database for storing data.
Vector Embedding: Ensures quick document search within the database.
Streamlit: Provides a user-friendly front end to display responses effectively.
Project Overview

In this notebook, we leverage the Mistral-7b-instruct model alongside the Langchain framework. The technique applied here is RAG, focusing on contextual training of LLMs rather than traditional fine-tuning.

Detailed Components and Usage
Large Language Model: Mistral-7b-instruct v0.3
Purpose: Text generation.
Benefits: Advanced capabilities for natural language understanding and generation.
Langchain Library
Purpose: Prompt engineering and developing the RAG application.
Benefits: Provides robust tools for building and managing prompts, enhancing the model's interaction with the user.
Chroma DB
Purpose: Vector database.
Benefits: Efficient data storage and retrieval, crucial for quick and accurate responses.
Transformer Embedding
Purpose: Quick document search.
Benefits: Ensures that relevant information is retrieved swiftly, improving the application's responsiveness.
Streamlit
Purpose: Front end and text streaming
Benefits: Offers an intuitive and visually appealing interface for users to interact with the application.

Retrieval Augmented Generation (RAG):
What is RAG?

Retrieval Augmented Generation is a technique that enhances the capabilities of LLMs by providing contextual training, as opposed to the traditional method of fine-tuning.

Advantages of RAG
Contextual Training: Provides more relevant and accurate responses by incorporating external data.
Flexibility: Allows the model to adapt to new information without the need for extensive retraining.
Efficiency: Reduces the time and computational resources required for fine-tuning.

With "Conversify AI," users can experience a seamless and efficient way to interact with web content, making it a powerful tool for extracting and summarizing information, answering questions, and more.

About

Conversify AI explore large contents.

Resources
 Readme
 Activity
Stars
 2 stars
Watchers
 1 watching
Forks
 1 fork


Releases
No releases published
Create a new release


Packages
No packages published
Publish your first package


Languages
Jupyter Notebook
69.1%
 
Python
30.9%
Footer
© 2024 GitHub, Inc.
Footer navigation
Terms
Privacy
Security
Status
Docs
Contact
Manage cookies
Do not share my personal information